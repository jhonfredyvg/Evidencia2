name: CI/CD Pipeline

on:
  push:
    branches: [ main, Rama1 ]
  pull_request:
    branches: [ main, Rama1 ]

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
          cache: 'pip'
          cache-dependency-path: requirements.txt
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run tests
        run: python -m unittest discover -s tests || true

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
          cache: 'pip'
          cache-dependency-path: requirements.txt
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run scraper
        run: python main.py
      - name: Commit and push CSV if exists
        run: |
          # Configurar git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Encontrar el Ãºltimo archivo CSV generado
          CSV_FILE=$(find datos -name "laptops_*.csv" | sort -V | tail -n 1)
          
          # Verificar si el archivo existe
          if [ -n "$CSV_FILE" ]; then
            echo "CSV file found: $CSV_FILE"
            git add "$CSV_FILE"
            git commit -m "Add latest scraping data: $CSV_FILE" || echo "No changes to commit"
            git push
          else
            echo "No CSV file found"
          fi
      - uses: actions/upload-artifact@v3
        with:
          name: scraped-data
          path: datos/laptops_*.csv